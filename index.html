<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
    <head>
        <meta name=viewport content="width=device-width, initial-scale=1">
            <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
                <style type="text/css">
                    /* Color scheme stolen from Sergey Karayev */
                    a {
                        color: #1772d0;
                        text-decoration:none;
                    }
                a:focus, a:hover {
                    color: #f09228;
                    text-decoration:none;
                }
                body,td,th,tr,p,a {
                    font-family: 'Lato', Verdana, Helvetica, sans-serif;
                    font-size: 14px
                }
                strong {
                    font-family: 'Lato', Verdana, Helvetica, sans-serif;
                    font-size: 14px;
                }
                heading {
                    font-family: 'Lato', Verdana, Helvetica, sans-serif;
                    font-size: 22px;
                }
                papertitle {
                    font-family: 'Lato', Verdana, Helvetica, sans-serif;
                    font-size: 14px;
                    font-weight: 700
                }
                name {
                    font-family: 'Lato', Verdana, Helvetica, sans-serif;
                    font-size: 32px;
                }
                .one
                {
                    width: 160px;
                    height: 160px;
                    position: relative;
                }
                .two
                {
                    width: 160px;
                    height: 160px;
                    position: absolute;
                    transition: opacity .2s ease-in-out;
                    -moz-transition: opacity .2s ease-in-out;
                    -webkit-transition: opacity .2s ease-in-out;
                }
                .fade {
                    transition: opacity .2s ease-in-out;
                    -moz-transition: opacity .2s ease-in-out;
                    -webkit-transition: opacity .2s ease-in-out;
                }
                span.highlight {
                    background-color: #ffffd0;
                }
                /* Page background */
                html {
                  background: #cdc !important;
                }
                </style>
                <link rel="icon" type="image/png" href="files/bham_icon.png">
                    <title>Ermano Arruda</title>
                    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
                        <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
                            

                            </head>
                            <body>
                            <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
                            <tr>
                            <td>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            <tr>
                            <td width="67%" valign="middle">
                            <p align="center">
                            <name>Ermano Arruda</name><br>
                            exa371 at bham dot ac dot uk
                            </p>
                            
                            <p>I completed my PhD in Computer Science at the <a href="http://www.cs.bham.ac.uk">University of Birmingham</a>. I was supervised by Prof. <a href="https://www.cs.bham.ac.uk/~jlw">Jeremy Wyatt</a> and Dr. <a href="https://www.cs.bham.ac.uk/~msk/">Marek Kopicki</a>. I worked in the <a href="https://www.cs.bham.ac.uk/research/groupings/robotics/"> Intelligent Robotics Lab</a>, where my research focus was applying machine learning for robotic manipulation.
                            </p>

                            <p>
                              I have worked on active vision for robotic grasping in the <a href="http://www.pacman-project.eu"> PaCMan project </a>.
                            </p>
                            <p>
                              Before being a postgraduate student, I received a Bachelors in Computer Science at the <a href="https://portal.cin.ufpe.br/"> Center for Informatics, Federal University of Pernambuco</a>.
                              I have also been part of the <a href="https://voxarlabs.cin.ufpe.br"> VoxarLabs </a>, where I worked on computer vision, augmented and virtual reality research and applications.
                            </p>
                            
    
                            <p align=center>
                            <a href="https://scholar.google.com/citations?hl=en&user=O60srhMAAAAJ">Google Scholar</a> &nbsp/&nbsp
                            <a href="http://www.github.com/eaa3/"> GitHub </a> &nbsp/&nbsp
                            <a href="http://www.linkedin.com/in/ermanoarruda/"> LinkedIn </a>
                            </p>
                            </td>
                            <td width="33%">
                            <img src="pic.jpg" style="width: 80%; height: 65%;">
                            </td>
                            </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            <tr>
                            <td width="100%" valign="middle">
                            <heading>Research</heading>
                            <p>
                              I am interested in how closing the loop between perception and action can improve performance in manipulation tasks for robotics. 
                              My research focus is robot perception, machine learning and control.
                           </p>
                            </td>
                            </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            
                             <tr onmouseout="unc_mppi_push_stop()" onmouseover="unc_mppi_push_start()" >

                              

                              <td width="25%">
            <!--                   <heading2><i>All Papers</i></heading2><br><br><br><br> -->

          
                              <div class="one">
                              <div class="two" id = 'unc_mppi_push_image'><img src='./files/unc_mppi_push.gif' width="160" height="160"></div>
                              <img src='./files/unc_mppi_push.jpg' width="160" height="160">>
                              </div>
                              <script type="text/javascript">
                              function unc_mppi_push_start() {
                              document.getElementById('unc_mppi_push_image').style.opacity = "1";
                              }
                              function unc_mppi_push_stop() {
                              document.getElementById('unc_mppi_push_image').style.opacity = "0";
                              }
                              unc_mppi_push_stop()
                              </script>
                              
                              </td>
                              <td valign="top" width="75%">
                                  <p><a href="https://arxiv.org/pdf/1710.04005.pdf">


                                  <papertitle>Uncertainty averse pushing with model predictive path integral control</papertitle></a><br>
                                  <strong>Ermano Arruda*</strong>, <a href="https://www.cs.bham.ac.uk/~mjm522">Michael J Mathew*</a>, <a href="https://www.cs.bham.ac.uk/~msk/">Marek Kopicki</a>, <a href="http://www.cs.bham.ac.uk/~mistrymn">Michael Mistry</a>, <a href="https://www.cs.bham.ac.uk/~azadm">Morteza Azad</a>, <a href="https://www.cs.bham.ac.uk/~jlw">Jeremy Wyatt</a><br/>(* equal contribution)<br/>
                                      <em>International Conference on Humanoid Robots (Humanoids)</em>, 2017<br/>
                                      <a href ="https://youtu.be/LjYruxwxkPM">video</a>
                                      /
                                      <a href="./files/bibtex/Arruda2017.bib">bibtex</a> <!--./files/bibtex/dummy.bib-->
                                      <p></p>
                                      <p>This work introduces a planner that makes use of an uncertain, learnt forward (dynamical) model to plan robust push manipulation. The forward model of the system is learned by poking the object in random directions and is then utilised by a model predictive path integral controller to push the box to a required goal location. By utilising path integral control, the proposed approach is able to avoid regions of high predictive uncertainty in the forward model. Thus, pushing tasks are completed in a robust fashion with respect to estimated uncertainty in the forward model and without the need of differentiable cost functions.</p>
                                  </a></p>
                              </td>
                            </tr>

                            <tr onmouseout="actv4g_stop()" onmouseover="actv4g_start()" >

                              

                              <td width="25%">
            <!--                   <heading2><i>All Papers</i></heading2><br><br><br><br> -->

          
                              <div class="one">
                              <div class="two" id = 'actv4g_image'><img src='./files/actv4g.gif' width="160" height="160"></div>
                              <img src='./files/actv4g.png' width="160" height="160">>
                              </div>
                              <script type="text/javascript">
                              function actv4g_start() {
                              document.getElementById('actv4g_image').style.opacity = "1";
                              }
                              function actv4g_stop() {
                              document.getElementById('actv4g_image').style.opacity = "0";
                              }
                              actv4g_stop()
                              </script>
                              
                              </td>
                              <td valign="top" width="75%">
                                  <p><a href="http://pure-oai.bham.ac.uk/ws/files/30318971/arruda_iros2016.pdf">


                                  <papertitle>Active vision for dexterous grasping of novel objects</papertitle></a><br>
                                  <strong>Ermano Arruda</strong>, <a href="https://www.cs.bham.ac.uk/~jlw">Jeremy Wyatt</a>, <a href="https://www.cs.bham.ac.uk/~msk/">Marek Kopicki</a> <br/>
                                      <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2016<br>
                                      <a href ="https://youtu.be/uBSOO6tMzwA">video</a>
                                      /
                                      <a href="./files/bibtex/Arruda2016.bib">bibtex</a>
                                      <p></p>
                                      <p>We tackled the problem of improving robot grasp performance using active vision. We sought to increase grasping success via two view selection heuristics: one that would allow the robot to explore good quality grasp contact points, and another that would permit the robot to investigate its workspace to make sure candidate grasp trajectories would not lead to collisions with unseen parts of the object to be grasped. Our results showed that this approach yielded better grasp success rate when compared to a random view selection strategy, while using fewer camera views for grasp planning. </p>
                                  </a></p>
                              </td>
                            </tr>


                            
                            
                      
                            
                        
                            <!-- <tr>
                                <td width="25%"><img src="./files/fshtk.png" alt="clean-usnob" width="160" height="160"></td>
                                <td width="75%" valign="top">
                                    <p>
                                    <p>
                                    <a href="#">
                                        <papertitle>Fishtank Everywhere: Improving Viewing Experience Over 3D Content</papertitle>
                                    </a>
                                    <br>
                                    
                                    <a href="http://cin.ufpe.br/~lsf/">Lucas Figueiredo*</a>, Edvar Vilar Neto, <strong>Ermano Arruda</strong>, Joao Marcelo Teixeira, <a href="http://cin.ufpe.br/~vt">Veronica Teichrieb</a><br>
                                    <em>International Conference on Human-Computer Interaction</em>, 2014<br/>
                                    <a href ="https://youtu.be/uBSOO6tMzwA">video</a>
                                      /
                                    <a href="./files/bibtex/Figueiredo2014.bib">bibtex</a>
                                    </p>
                                    <p></p>
                                    
                                    <br>
                                    </p>
                                    </p>
                                </td>
                            </tr> -->
                            </table>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tr>
                                    <td>
                                        <heading>Workshops</heading>
                                    </td>
                                </tr>
                            </table>

                            <table width="100%" align="center" border="0" cellpadding="20">
                                <tr onmouseout="pggs_stop()" onmouseover="pggs_start()">


                                    <td width="25%">

                                      <div class="one">
                                      <div class="two" id = 'pggs_image'><img src='./files/short_pggs_desc.gif' width="160" height="160"></div>
                                      <img src='./files/pggs_rss2019.png' width="160" height="160">>
                                      </div>
                                      <script type="text/javascript">
                                      function pggs_start() {
                                      document.getElementById('pggs_image').style.opacity = "1";
                                      }
                                      function pggs_stop() {
                                      document.getElementById('pggs_image').style.opacity = "0";
                                      }
                                      pggs_stop()
                                      </script>

                                    </td>
                                    <td width="75%" valign="top">
                                        <p>
                                        <a href="https://arxiv.org/pdf/1906.11548">
                                            <papertitle>Generative grasp synthesis from demonstration using parametric mixtures</papertitle>
                                        </a>

                                        <br>
                                        <strong>Ermano Arruda</strong>, <a href="https://www.memnone.net"> Claudio Zito</a>, <a href="https://www.cs.bham.ac.uk/~sridharm/">Mohan Sridharan</a>, <a href="https://www.cs.bham.ac.uk/~msk/">Marek Kopicki</a>, <a href="https://www.cs.bham.ac.uk/~jlw/">Jeremy L. Wyatt</a>
                                        <br><em> <a href="https://lcas.lincoln.ac.uk/wp/tig-ii/">Task-Informed Grasping (TIG-II): From Perception to Physical Interaction</a>, Robotics: Science and Systems (RSS)</em>, 2019.<br>
                                        <a href ="https://youtu.be/9RqZaTAH4Fs">video</a>
                                        /
                                        <a href="./files/bibtex/ArrudaTIGRSS2019.bib">bibtex</a>
                                        <p><br>
                                          We present a parametric formulation for learning generative models for grasp synthesis from a demonstration. 
                                          We cast new light on this family of approaches, proposing a parametric formulation for grasp synthesis that is computationally faster compared to related work and indicates better grasp success rate performance in simulated experiments. 
                                          The proposed implementation is also able to incorporate arbitrary constraints for grasp ranking that may include task-specific constraints. Results are reported followed by a brief discussion on the merits of the proposed methods noted so far.
                                        </p>
                                        </p>
                                    </td>
                                </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tr>
                                    <td>
                                        <heading>Course Projects</heading>
                                    </td>
                                </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellpadding="20">
                                <tr onmouseout="stbslam_stop()" onmouseover="stbslam_start()">


                                    <td width="25%">

                                      <div class="one">
                                      <div class="two" id = 'stbslam_image'><img src='./files/stb_slam.gif' width="160" height="160"></div>
                                      <img src='./files/stb_slam.png' width="160" height="160">>
                                      </div>
                                      <script type="text/javascript">
                                      function stbslam_start() {
                                      document.getElementById('stbslam_image').style.opacity = "1";
                                      }
                                      function stbslam_stop() {
                                      document.getElementById('stbslam_image').style.opacity = "0";
                                      }
                                      stbslam_stop()
                                      </script>

                                    </td>
                                    <td width="75%" valign="top">
                                        <p>
                                        <a href="https://www.cin.ufpe.br/~tg/2015-1/eaa3.pdf">
                                            <papertitle>A study on SLAM techniques with applications on robot perception</papertitle>
                                        </a>

                                        <br>
                                        <strong>Ermano Arruda</strong>, <a href="http://cin.ufpe.br/~vt">Veronica Teichrieb</a>, <a href="http://cin.ufpe.br/~jpsml/">Joao Paulo Lima</a>, 2015
                                        <br>
                                        <a href ="https://youtu.be/-ZV9gk_Hw84">video</a>
                                        <p><br>
                                          In my final year project I have implemented a Graph SLAM (Simultaneous Localisation and Mapping) system for mobile robots.
                                          The system was quantitatively evaluated on the <a href="https://vision.in.tum.de/data/datasets/rgbd-dataset"> TUM RGB-D SLAM Benchmark </a> dataset. 
                                          The final system was able to successfully map a whole flat using <a href="http://www.robots.ox.ac.uk/~mjc/Software.htm"> FAB-MAP </a> for loop-closure detection.
                                        </p>
                                        </p>
                                    </td>
                                </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tr>
                                    <td>
                                        <heading>Awards</heading>
                                    </td>
                                </tr>
                            </table>
                            <table width="100%" align="center" border="0" cellpadding="20">
                                <tr>
                                    <td width="25%"><img src="./files/stam.png" alt="pacman" width="160" height="160"></td>
                                    <td width="75%" valign="center">
                                        <p>
                                        <ul>
                                        <li>First place at ISMAR Off-site Tracking Competition, Fukuoka, Japan, 2015. Developed a monocular visual odometry system with additional sparse bundle adjustment for camera trajectory optimisation.</li>

                                        </p>
                                        <p>
                                          <a href="https://youtu.be/x5cfiTduKyM"> video1 </a>
                                          /
                                          <a href="https://youtu.be/-tktpdMwsVs"> video2 </a>
                                        </p>
                                        <p>
                                          <a href="https://github.com/eaa3/STAM"> code </a>
                                        </p>
                                    </td>
                                </tr>
                                <tr>
                                    <td width="25%"><img src="./files/izak.png" alt="pacman" width="160" height="160"></td>
                                    <td width="75%" valign="center">
                                        <p>
                                        <ul>
                                        <li>Winning team CESAR-VoxarLabs at LARC/CBR - Latin American and Brazilian Robotics Competition, RoboCup@Home, 2014. Worked on object-tracking and detection system.</li>
                                        </p>

                                        <p>
                                          <a href="http://www.i-zak.org"> meet i-zak </a>
                                        </p>
                                    </td>
                                </tr>
                                <!-- <tr>
                                    <td width="25%"><img src="./files/anmr.png" alt="pacman" width="160" height="160"></td>
                                    <td width="75%" valign="center">
                                        <p>
                                        <ul>
                                        <li>AnimAR application - Grand Prize Winner for Metaio's GotHeARt Competition (InsideAR, Munich, Germany), 2013. An augmented reality application for storyboard design and animation.</li>
                                        </p>
                                        <p>
                                          <a href="https://youtu.be/JFZ3TQxPRVk"> video </a>
                                        </p>
                                    </td>
                                </tr> -->
                            </table>

                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody><tr>
        <td>
        <heading>Teaching</heading>
        </td>
      </tr>
      </tbody></table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tbody><tr>
        <td width="25%"><img src="./files/teaching_icon.jpg" alt="teach" width="160" height="160"></td>
        <td width="75%" valign="center">
          <p>

        <a href="https://www.cs.bham.ac.uk/internal/modules/2017/06-13520/">
          <papertitle>06-13520: Intelligent Robotics</papertitle>
        </a><br>
        Teaching Assistant (TA)
        <br><br>

        <a href="https://www.cs.bham.ac.uk/internal/modules/2016/06-28912/">
          <papertitle>06-28912: Graphics</papertitle>
        </a><br>
        Teaching Assistant (TA)
        <br><br>
        

          <a href="https://www.cs.bham.ac.uk/internal/modules/2016/06-27821/">
          <papertitle>06-27821: Software Workshop 1</papertitle>
        </a><br>
        Teaching Assistant (TA)
        <br><br>

      

        </p>
        </td>
      </tr>
      </tbody></table>

                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            <tbody><tr>
                              <td>
                              <br>
                              <p align="right"><font size="2">
                                <a href="https://people.eecs.berkeley.edu/~barron/">This webpage is really nice.</a>
                                </font>
                              </p>
                              </td>
                            </tr>
                            </tbody>
                           </table>

                           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                            <tbody><tr>
                              <td>
                              <br>
                              <center>
                              <a href="#diary_frame" onclick="toggle_diary()">Toggle diary</a>
                              <iframe id="diary_frame" src="https://calendar.google.com/calendar/embed?mode=WEEK&amp;height=600&amp;wkst=1&amp;bgcolor=%23FFFFFF&amp;src=ermano.arruda%40gmail.com&amp;color=%232952A3&amp;src=ocbtu0bbvq6b97m0o90jtnhjco%40group.calendar.google.com&amp;color=%235F6B02&amp;ctz=Europe%2FLondon" style="border-width:0" width="800" height="600" frameborder="0" scrolling="no"></iframe>
                              </center>
                              <script type="text/javascript">
                                      function toggle_diary() {

                                      var current_display = document.getElementById('diary_frame').style.display;
                                      if(current_display != "none"){
                                        document.getElementById('diary_frame').style.display = "none";
                                      }
                                      else {
                                        document.getElementById('diary_frame').style.display = "block";
                                      }
                                      }
                                
                                      toggle_diary()
                              </script>
                              </td>
                            </tr>
                            </tbody>
                           </table>

                          
                                </td>
                                </tr>
                                </table>
                                </body>
</html>

